{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvJQz3P3IQ0EUrLuTKVqnA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bulle3/just-do-it/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6Yyx3PdlLcT",
        "outputId": "dcf3d081-9c1e-45a3-b0a4-baed923f4a75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_binary(text):\n",
        "    binary = ''.join(format(ord(char), '08b') for char in text)\n",
        "    return binary\n",
        "\n",
        "text = 'Hello World'\n",
        "binary = text_to_binary(text)\n",
        "\n",
        "print(f'The binary representation of \"{text}\" is:')\n",
        "print(binary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTZOR46ZlMNS",
        "outputId": "62d37a0c-4d7e-4a87-99eb-6e78e05e9277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The binary representation of \"Hello World\" is:\n",
            "0100100001100101011011000110110001101111001000000101011101101111011100100110110001100100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "\n",
        "# Define the autoencoder\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Linear(input_size, hidden_size)\n",
        "        self.decoder = nn.Linear(hidden_size, input_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.sigmoid(self.encoder(x))\n",
        "        x = torch.sigmoid(self.decoder(x))\n",
        "        return x\n",
        "\n",
        "# Load your data here\n",
        "# my_data = load_your_data()\n",
        "\n",
        "# Convert your data to a PyTorch tensor\n",
        "# inputs = torch.Tensor(my_data)\n",
        "\n",
        "# Size of the hidden layer\n",
        "hidden_size = 128\n",
        "\n",
        "# Initialize the autoencoder, loss function, and optimizer\n",
        "autoencoder = Autoencoder(inputs.shape[1], hidden_size)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = Adam(autoencoder.parameters())\n",
        "\n",
        "# Number of epochs (complete passes through the dataset)\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Zero the gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = autoencoder(inputs)\n",
        "\n",
        "    # Compute the loss\n",
        "    loss = criterion(outputs, inputs)\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Update the weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print the loss for this epoch\n",
        "    print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gj6hDyhSmFDC",
        "outputId": "aff60420-8c65-45b8-f4d8-995b52262722"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Loss: 0.25535067915916443\n",
            "Epoch 2/100, Loss: 0.2525624930858612\n",
            "Epoch 3/100, Loss: 0.2511420249938965\n",
            "Epoch 4/100, Loss: 0.25046592950820923\n",
            "Epoch 5/100, Loss: 0.2501452565193176\n",
            "Epoch 6/100, Loss: 0.2499840408563614\n",
            "Epoch 7/100, Loss: 0.24989376962184906\n",
            "Epoch 8/100, Loss: 0.24983589351177216\n",
            "Epoch 9/100, Loss: 0.24979348480701447\n",
            "Epoch 10/100, Loss: 0.2497587651014328\n",
            "Epoch 11/100, Loss: 0.2497275024652481\n",
            "Epoch 12/100, Loss: 0.2496972233057022\n",
            "Epoch 13/100, Loss: 0.2496662139892578\n",
            "Epoch 14/100, Loss: 0.24963337182998657\n",
            "Epoch 15/100, Loss: 0.24959805607795715\n",
            "Epoch 16/100, Loss: 0.24956008791923523\n",
            "Epoch 17/100, Loss: 0.2495194971561432\n",
            "Epoch 18/100, Loss: 0.24947644770145416\n",
            "Epoch 19/100, Loss: 0.24943111836910248\n",
            "Epoch 20/100, Loss: 0.2493836134672165\n",
            "Epoch 21/100, Loss: 0.249333918094635\n",
            "Epoch 22/100, Loss: 0.2492818534374237\n",
            "Epoch 23/100, Loss: 0.24922692775726318\n",
            "Epoch 24/100, Loss: 0.24916867911815643\n",
            "Epoch 25/100, Loss: 0.24910670518875122\n",
            "Epoch 26/100, Loss: 0.24904067814350128\n",
            "Epoch 27/100, Loss: 0.24897044897079468\n",
            "Epoch 28/100, Loss: 0.2488957941532135\n",
            "Epoch 29/100, Loss: 0.2488163709640503\n",
            "Epoch 30/100, Loss: 0.2487318068742752\n",
            "Epoch 31/100, Loss: 0.24864165484905243\n",
            "Epoch 32/100, Loss: 0.24854543805122375\n",
            "Epoch 33/100, Loss: 0.24844279885292053\n",
            "Epoch 34/100, Loss: 0.2483334094285965\n",
            "Epoch 35/100, Loss: 0.24821695685386658\n",
            "Epoch 36/100, Loss: 0.24809303879737854\n",
            "Epoch 37/100, Loss: 0.24796147644519806\n",
            "Epoch 38/100, Loss: 0.24782226979732513\n",
            "Epoch 39/100, Loss: 0.2476755827665329\n",
            "Epoch 40/100, Loss: 0.24752137064933777\n",
            "Epoch 41/100, Loss: 0.2473597526550293\n",
            "Epoch 42/100, Loss: 0.24719101190567017\n",
            "Epoch 43/100, Loss: 0.2470158040523529\n",
            "Epoch 44/100, Loss: 0.24683533608913422\n",
            "Epoch 45/100, Loss: 0.2466505914926529\n",
            "Epoch 46/100, Loss: 0.24646255373954773\n",
            "Epoch 47/100, Loss: 0.2462720423936844\n",
            "Epoch 48/100, Loss: 0.246079683303833\n",
            "Epoch 49/100, Loss: 0.24588553607463837\n",
            "Epoch 50/100, Loss: 0.2456888109445572\n",
            "Epoch 51/100, Loss: 0.24548889696598053\n",
            "Epoch 52/100, Loss: 0.24528543651103973\n",
            "Epoch 53/100, Loss: 0.24507786333560944\n",
            "Epoch 54/100, Loss: 0.24486491084098816\n",
            "Epoch 55/100, Loss: 0.24464543163776398\n",
            "Epoch 56/100, Loss: 0.2444194108247757\n",
            "Epoch 57/100, Loss: 0.2441871613264084\n",
            "Epoch 58/100, Loss: 0.24394892156124115\n",
            "Epoch 59/100, Loss: 0.2437044382095337\n",
            "Epoch 60/100, Loss: 0.24345387518405914\n",
            "Epoch 61/100, Loss: 0.24319741129875183\n",
            "Epoch 62/100, Loss: 0.24293504655361176\n",
            "Epoch 63/100, Loss: 0.24266661703586578\n",
            "Epoch 64/100, Loss: 0.2423921376466751\n",
            "Epoch 65/100, Loss: 0.24211178719997406\n",
            "Epoch 66/100, Loss: 0.2418259084224701\n",
            "Epoch 67/100, Loss: 0.24153463542461395\n",
            "Epoch 68/100, Loss: 0.24123786389827728\n",
            "Epoch 69/100, Loss: 0.2409355491399765\n",
            "Epoch 70/100, Loss: 0.24062781035900116\n",
            "Epoch 71/100, Loss: 0.24031485617160797\n",
            "Epoch 72/100, Loss: 0.2399967759847641\n",
            "Epoch 73/100, Loss: 0.2396737039089203\n",
            "Epoch 74/100, Loss: 0.23934581875801086\n",
            "Epoch 75/100, Loss: 0.23901315033435822\n",
            "Epoch 76/100, Loss: 0.23867563903331757\n",
            "Epoch 77/100, Loss: 0.23833318054676056\n",
            "Epoch 78/100, Loss: 0.23798562586307526\n",
            "Epoch 79/100, Loss: 0.23763297498226166\n",
            "Epoch 80/100, Loss: 0.23727525770664215\n",
            "Epoch 81/100, Loss: 0.2369125932455063\n",
            "Epoch 82/100, Loss: 0.23654499650001526\n",
            "Epoch 83/100, Loss: 0.23617257177829742\n",
            "Epoch 84/100, Loss: 0.23579542338848114\n",
            "Epoch 85/100, Loss: 0.23541367053985596\n",
            "Epoch 86/100, Loss: 0.23502741754055023\n",
            "Epoch 87/100, Loss: 0.23463693261146545\n",
            "Epoch 88/100, Loss: 0.2342424839735031\n",
            "Epoch 89/100, Loss: 0.2338443249464035\n",
            "Epoch 90/100, Loss: 0.23344282805919647\n",
            "Epoch 91/100, Loss: 0.23303841054439545\n",
            "Epoch 92/100, Loss: 0.23263141512870789\n",
            "Epoch 93/100, Loss: 0.23222221434116364\n",
            "Epoch 94/100, Loss: 0.23181088268756866\n",
            "Epoch 95/100, Loss: 0.23139743506908417\n",
            "Epoch 96/100, Loss: 0.23098190128803253\n",
            "Epoch 97/100, Loss: 0.2305641770362854\n",
            "Epoch 98/100, Loss: 0.23014412820339203\n",
            "Epoch 99/100, Loss: 0.22972160577774048\n",
            "Epoch 100/100, Loss: 0.22929660975933075\n"
          ]
        }
      ]
    }
  ]
}